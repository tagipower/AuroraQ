import os
import torch
from stable_baselines3 import PPO

class PPOAgentTrainable:
    def __init__(self, env):
        """
        PPOAgentTrainable ê°ì²´ë¥¼ ì´ˆê¸°í™”í•˜ë©° í™˜ê²½ envë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
        """
        self.name = "PPO"
        self.model = None
        self.env = env

    def train(self, timesteps=10000):
        """
        PPO ëª¨ë¸ì„ ì§€ì •ëœ í™˜ê²½ì—ì„œ í•™ìŠµí•©ë‹ˆë‹¤.
        í•™ìŠµ ì™„ë£Œ í›„ í‰ê·  ë³´ìƒê°’(mean_reward)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        self.model = PPO("MlpPolicy", self.env, verbose=1)
        self.model.learn(total_timesteps=timesteps)

        # ì—í”¼ì†Œë“œ ë³´ìƒ í‰ê·  ê³„ì‚°
        if hasattr(self.env, 'get_episode_rewards'):
            rewards = self.env.get_episode_rewards()
            if rewards:
                mean_reward = sum(rewards) / len(rewards)
                return {"mean_reward": mean_reward}

        return {"mean_reward": None}

    def save_model(self, zip_path, pt_path=None):
        """
        í•™ìŠµëœ PPO ëª¨ë¸ì„ zip ë° ì„ íƒì ìœ¼ë¡œ pt í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        """
        if self.model:
            self.model.save(zip_path)
            print(f"[PPOAgentTrainable] âœ… zip ì €ì¥ë¨: {zip_path}")
            if pt_path:
                torch.save(self.model.policy.state_dict(), pt_path)
                print(f"[PPOAgentTrainable] âœ… pt ì €ì¥ë¨: {pt_path}")
        else:
            raise RuntimeError("[PPOAgentTrainable] ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def load_model(self, zip_path):
        """
        ì €ì¥ëœ zip ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
        """
        if os.path.exists(zip_path):
            self.model = PPO.load(zip_path)
            print(f"[PPOAgentTrainable] ğŸ“¦ zip ëª¨ë¸ ë¡œë“œë¨: {zip_path}")
        else:
            raise FileNotFoundError(f"[PPOAgentTrainable] âŒ zip íŒŒì¼ ì—†ìŒ: {zip_path}")

    def predict(self, obs):
        """
        í˜„ì¬ ìƒíƒœì— ëŒ€í•´ ì˜ˆì¸¡ëœ í–‰ë™ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if self.model:
            action, _ = self.model.predict(obs, deterministic=True)
            return action
        else:
            raise RuntimeError("[PPOAgentTrainable] ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    def score(self):
        """
        PPO ì „ëµ ì ìˆ˜í™” í•¨ìˆ˜.
        í•™ìŠµëœ í™˜ê²½ì˜ í‰ê·  ë³´ìƒ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°.
        """
        if hasattr(self.env, 'get_episode_rewards'):
            rewards = self.env.get_episode_rewards()
            if rewards:
                mean_reward = sum(rewards) / len(rewards)
                total_score = round(mean_reward, 4)
                return {
                    "total_score": total_score,
                    "mean_reward": round(mean_reward, 4),
                    "score_type": "mean_reward"
                }
        return {
            "total_score": 0.0,
            "mean_reward": 0.0,
            "score_type": "none"
        }
