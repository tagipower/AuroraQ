#!/usr/bin/env python3
"""
ìµœì í™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
"""

import pytest
import numpy as np
import pandas as pd
import json
import os
from datetime import datetime
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

from utils import get_logger, PerformanceMetrics, calculate_sharpe_ratio

logger = get_logger("TestOptimization")

class TestOptimization:
    """ìµœì í™” í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def setup_method(self):
        """í…ŒìŠ¤íŠ¸ ì…‹ì—…"""
        self.test_data = self._create_test_data()
        self.test_trades = self._create_test_trades()
    
    def _create_test_data(self) -> pd.DataFrame:
        """í…ŒìŠ¤íŠ¸ìš© ê°€ê²© ë°ì´í„° ìƒì„±"""
        np.random.seed(42)
        dates = pd.date_range(start='2024-01-01', periods=200, freq='H')
        
        # íŠ¸ë Œë“œê°€ ìˆëŠ” ê°€ê²© ì‹œë®¬ë ˆì´ì…˜
        trend = np.linspace(0, 0.2, 200)  # 20% ìƒìŠ¹ íŠ¸ë Œë“œ
        noise = np.random.normal(0, 0.02, 200)
        price_changes = trend + noise
        
        prices = 50000 * np.cumprod(1 + price_changes / 100)
        
        return pd.DataFrame({
            'timestamp': dates,
            'open': prices * np.random.uniform(0.998, 1.002, 200),
            'high': prices * np.random.uniform(1.001, 1.005, 200),
            'low': prices * np.random.uniform(0.995, 0.999, 200),
            'close': prices,
            'volume': np.random.randint(100000, 1000000, 200)
        })
    
    def _create_test_trades(self) -> list:
        """í…ŒìŠ¤íŠ¸ìš© ê±°ë˜ ë‚´ì—­ ìƒì„±"""
        trades = []
        
        # 10ê°œì˜ ëª¨ì˜ ê±°ë˜ ìƒì„±
        for i in range(10):
            # ê°œì‹œ ê±°ë˜
            open_trade = {
                'action': 'open',
                'size': 0.01 * (1 if i % 2 == 0 else -1),  # ë§¤ìˆ˜/ë§¤ë„ êµëŒ€
                'price': 50000 + i * 100,
                'timestamp': datetime(2024, 1, 1, i),
                'signal_info': {'strategy': 'test', 'confidence': 0.7}
            }
            trades.append(open_trade)
            
            # ì²­ì‚° ê±°ë˜
            close_trade = {
                'action': 'close',
                'size': -open_trade['size'],
                'price': open_trade['price'] * (1 + np.random.normal(0.01, 0.02)),  # 1% í‰ê·  ìˆ˜ìµ
                'timestamp': datetime(2024, 1, 1, i, 30),  # 30ë¶„ í›„ ì²­ì‚°
                'pnl': 0,  # ê³„ì‚°ë  ì˜ˆì •
                'pnl_pct': 0,  # ê³„ì‚°ë  ì˜ˆì •
                'holding_time': pd.Timedelta(minutes=30),
                'reason': 'test'
            }
            
            # PnL ê³„ì‚°
            pnl = (close_trade['price'] - open_trade['price']) * open_trade['size']
            pnl_pct = pnl / abs(open_trade['size'] * open_trade['price'])
            
            close_trade['pnl'] = pnl
            close_trade['pnl_pct'] = pnl_pct
            
            trades.append(close_trade)
        
        return trades
    
    def test_performance_metrics_calculation(self):
        """ì„±ê³¼ ì§€í‘œ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        from utils.metrics import calculate_performance_metrics
        
        metrics = calculate_performance_metrics(self.test_trades)
        
        # ê¸°ë³¸ ê²€ì¦
        assert isinstance(metrics, PerformanceMetrics)
        assert metrics.total_trades == 10  # 10ê°œ ê±°ë˜
        assert 0 <= metrics.win_rate <= 1  # ìŠ¹ë¥ ì€ 0-1 ì‚¬ì´
        assert metrics.profit_factor >= 0  # ì´ìµ íŒ©í„°ëŠ” 0 ì´ìƒ
        
        logger.info(f"ì´ ê±°ë˜: {metrics.total_trades}")
        logger.info(f"ìŠ¹ë¥ : {metrics.win_rate:.2%}")
        logger.info(f"ìƒ¤í”„ ë¹„ìœ¨: {metrics.sharpe_ratio:.3f}")
        logger.info(f"ìµœëŒ€ ë‚™í­: {metrics.max_drawdown:.2%}")
    
    def test_sharpe_ratio_calculation(self):
        """ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥  ë°ì´í„°
        returns = [0.01, -0.005, 0.02, 0.015, -0.01, 0.008, 0.012, -0.003, 0.018, 0.005]
        
        sharpe = calculate_sharpe_ratio(returns)
        
        assert isinstance(sharpe, float)
        assert not np.isnan(sharpe)
        
        logger.info(f"ìƒ¤í”„ ë¹„ìœ¨: {sharpe:.3f}")
        
        # ë¹ˆ ë¦¬ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
        empty_sharpe = calculate_sharpe_ratio([])
        assert empty_sharpe == 0.0
        
        # ë‹¨ì¼ ê°’ í…ŒìŠ¤íŠ¸
        single_sharpe = calculate_sharpe_ratio([0.01])
        assert single_sharpe == 0.0
    
    def test_combination_optimizer_loading(self):
        """ì¡°í•© ìµœì í™”ê¸° ë¡œë”© í…ŒìŠ¤íŠ¸"""
        try:
            sys.path.append(os.path.dirname(parent_dir))
            from optimization.optimal_combination_recommender import OptimalCombinationRecommender
            
            optimizer = OptimalCombinationRecommender()
            assert optimizer is not None
            
            logger.info("ì¡°í•© ìµœì í™”ê¸° ë¡œë”© ì„±ê³µ")
            
        except ImportError as e:
            logger.warning(f"ì¡°í•© ìµœì í™”ê¸° ë¡œë”© ì‹¤íŒ¨: {e}")
            pytest.skip("ìµœì í™” ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def test_grid_search_optimization(self):
        """ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™” í…ŒìŠ¤íŠ¸"""
        try:
            sys.path.append(os.path.dirname(parent_dir))
            from optimization.optimal_combination_recommender import OptimalCombinationRecommender
            
            optimizer = OptimalCombinationRecommender()
            
            # ì‘ì€ ê·¸ë¦¬ë“œë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
            results = optimizer.grid_search_optimization(
                price_data=self.test_data,
                ppo_weights=[0.3, 0.4],
                rule_weights=[0.2, 0.3],
                hybrid_modes=["ensemble"],
                execution_strategies=["market"],
                max_combinations=4
            )
            
            # ê²°ê³¼ ê²€ì¦
            assert "optimization_method" in results
            assert "total_combinations_tested" in results
            assert "best_combination" in results
            
            if results["best_combination"]:
                best = results["best_combination"]
                assert "weights" in best
                assert "hybrid_mode" in best
                assert "execution_strategy" in best
                assert "combined_score" in best
            
            logger.info(f"í…ŒìŠ¤íŠ¸ëœ ì¡°í•© ìˆ˜: {results['total_combinations_tested']}")
            
        except Exception as e:
            logger.warning(f"ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            pytest.skip("ìµœì í™” í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def test_optimization_results_loading(self):
        """ìµœì í™” ê²°ê³¼ ë¡œë”© í…ŒìŠ¤íŠ¸"""
        # ê¸°ì¡´ ìµœì í™” ê²°ê³¼ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        results_dir = os.path.join(os.path.dirname(parent_dir), "optimization", "results")
        
        if os.path.exists(results_dir):
            result_files = [f for f in os.listdir(results_dir) if f.startswith("optimal_combinations_")]
            
            if result_files:
                latest_file = sorted(result_files)[-1]
                file_path = os.path.join(results_dir, latest_file)
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
                    assert "optimization_method" in data
                    assert "best_combination" in data
                    
                    if data["best_combination"]:
                        best = data["best_combination"]
                        assert "weights" in best
                        assert "hybrid_mode" in best
                        assert "execution_strategy" in best
                    
                    logger.info(f"ìµœì í™” ê²°ê³¼ ë¡œë”© ì„±ê³µ: {latest_file}")
                    
                except Exception as e:
                    logger.warning(f"ìµœì í™” ê²°ê³¼ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            else:
                logger.info("ìµœì í™” ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            logger.info("ìµœì í™” ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    def test_strategy_weight_calculation(self):
        """ì „ëµ ê°€ì¤‘ì¹˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        try:
            sys.path.append(os.path.dirname(parent_dir))
            from optimization.optimal_combination_recommender import StrategyWeight
            
            # ê°€ì¤‘ì¹˜ ê°ì²´ ìƒì„±
            weight = StrategyWeight(
                ppo_weight=0.4,
                rule_a_weight=0.2,
                rule_b_weight=0.2,
                rule_c_weight=0.2
            )
            
            # ì •ê·œí™” í…ŒìŠ¤íŠ¸
            weight.normalize()
            
            total = weight.ppo_weight + weight.rule_a_weight + weight.rule_b_weight + weight.rule_c_weight
            assert abs(total - 1.0) < 1e-6  # í•©ì´ 1ì— ê°€ê¹Œì›Œì•¼ í•¨
            
            # ë”•ì…”ë„ˆë¦¬ ë³€í™˜ í…ŒìŠ¤íŠ¸
            weight_dict = weight.to_dict()
            assert "ppo" in weight_dict
            assert "rule_a" in weight_dict
            assert "rule_b" in weight_dict
            assert "rule_c" in weight_dict
            
            logger.info("ì „ëµ ê°€ì¤‘ì¹˜ ê³„ì‚° ê²€ì¦ ì™„ë£Œ")
            
        except ImportError as e:
            logger.warning(f"ì „ëµ ê°€ì¤‘ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            pytest.skip("ì „ëµ ê°€ì¤‘ì¹˜ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def test_performance_report_formatting(self):
        """ì„±ê³¼ ë¦¬í¬íŠ¸ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"""
        from utils.metrics import calculate_performance_metrics, format_performance_report
        
        metrics = calculate_performance_metrics(self.test_trades)
        report = format_performance_report(metrics)
        
        assert isinstance(report, str)
        assert len(report) > 0
        assert "ìˆ˜ìµë¥ " in report
        assert "ìŠ¹ë¥ " in report
        assert "ìƒ¤í”„ ë¹„ìœ¨" in report
        
        logger.info("ì„±ê³¼ ë¦¬í¬íŠ¸ í¬ë§·íŒ… ê²€ì¦ ì™„ë£Œ")

if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    test_class = TestOptimization()
    
    print("ğŸ§ª ìµœì í™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        test_class.setup_method()
        
        print("1/7: ì„±ê³¼ ì§€í‘œ ê³„ì‚° í…ŒìŠ¤íŠ¸")
        test_class.test_performance_metrics_calculation()
        print("âœ… í†µê³¼")
        
        print("2/7: ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚° í…ŒìŠ¤íŠ¸")
        test_class.test_sharpe_ratio_calculation()
        print("âœ… í†µê³¼")
        
        print("3/7: ì¡°í•© ìµœì í™”ê¸° ë¡œë”© í…ŒìŠ¤íŠ¸")
        test_class.test_combination_optimizer_loading()
        print("âœ… í†µê³¼")
        
        print("4/7: ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™” í…ŒìŠ¤íŠ¸")
        test_class.test_grid_search_optimization()
        print("âœ… í†µê³¼")
        
        print("5/7: ìµœì í™” ê²°ê³¼ ë¡œë”© í…ŒìŠ¤íŠ¸")
        test_class.test_optimization_results_loading()
        print("âœ… í†µê³¼")
        
        print("6/7: ì „ëµ ê°€ì¤‘ì¹˜ ê³„ì‚° í…ŒìŠ¤íŠ¸")
        test_class.test_strategy_weight_calculation()
        print("âœ… í†µê³¼")
        
        print("7/7: ì„±ê³¼ ë¦¬í¬íŠ¸ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸")
        test_class.test_performance_report_formatting()
        print("âœ… í†µê³¼")
        
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()