#!/usr/bin/env python3
"""
VPS Deployment ì‹œìŠ¤í…œ ê²€ì¦ê¸°
ì„í¬íŠ¸, ì˜ì¡´ì„±, ìµœì í™”, ì—”ë“œí¬ì¸íŠ¸, ë³´ì•ˆ ë“± ì „ì²´ ê²€ì¦
"""

import ast
import asyncio
import json
import os
import sys
import time
import traceback
import importlib
import psutil
import gc
from pathlib import Path
from typing import Dict, List, Any, Set, Optional
from datetime import datetime
from collections import defaultdict
import subprocess
import requests
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class SystemValidator:
    """ì‹œìŠ¤í…œ ì „ì²´ ê²€ì¦ê¸°"""
    
    def __init__(self, root_path: str = None):
        self.root_path = Path(root_path) if root_path else Path(__file__).parent
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'validation_results': {}
        }
        
    def analyze_imports(self) -> Dict[str, Any]:
        """ì„í¬íŠ¸ ì˜ì¡´ì„± ë¶„ì„"""
        logger.info("ğŸ” ì„í¬íŠ¸ ì˜ì¡´ì„± ë¶„ì„ ì‹œì‘...")
        
        import_analysis = {
            'python_files': [],
            'import_graph': defaultdict(set),
            'external_dependencies': set(),
            'internal_dependencies': set(),
            'circular_imports': [],
            'missing_imports': [],
            'unused_imports': [],
            'optimization_suggestions': []
        }
        
        # Python íŒŒì¼ ì°¾ê¸°
        python_files = list(self.root_path.rglob("*.py"))
        import_analysis['python_files'] = [str(f.relative_to(self.root_path)) for f in python_files]
        
        # ê° íŒŒì¼ì˜ ì„í¬íŠ¸ ë¶„ì„
        for py_file in python_files:
            if py_file.name.startswith('.') or '__pycache__' in str(py_file):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                file_imports = self._extract_imports(tree)
                
                rel_path = str(py_file.relative_to(self.root_path))
                import_analysis['import_graph'][rel_path] = file_imports
                
                # ì™¸ë¶€/ë‚´ë¶€ ì˜ì¡´ì„± ë¶„ë¥˜
                for imp in file_imports:
                    if imp.startswith('.') or any(part in imp for part in ['trading', 'sentiment-service', 'vps_logging']):
                        import_analysis['internal_dependencies'].add(imp)
                    else:
                        import_analysis['external_dependencies'].add(imp)
                        
            except Exception as e:
                logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {py_file}: {e}")
        
        # ìˆœí™˜ ì„í¬íŠ¸ ê²€ì‚¬
        import_analysis['circular_imports'] = self._detect_circular_imports(import_analysis['import_graph'])
        
        # ëˆ„ë½ëœ ì„í¬íŠ¸ ê²€ì‚¬
        import_analysis['missing_imports'] = self._check_missing_imports(import_analysis['import_graph'])
        
        # ìµœì í™” ì œì•ˆ
        import_analysis['optimization_suggestions'] = self._generate_import_optimizations(import_analysis)
        
        return import_analysis
    
    def _extract_imports(self, tree: ast.AST) -> Set[str]:
        """ASTì—ì„œ ì„í¬íŠ¸ ì¶”ì¶œ"""
        imports = set()
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.add(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.add(node.module)
        
        return imports
    
    def _detect_circular_imports(self, import_graph: Dict[str, Set[str]]) -> List[List[str]]:
        """ìˆœí™˜ ì„í¬íŠ¸ íƒì§€"""
        circular = []
        visited = set()
        rec_stack = set()
        
        def dfs(node, path):
            if node in rec_stack:
                # ìˆœí™˜ ë°œê²¬
                cycle_start = path.index(node)
                cycle = path[cycle_start:] + [node]
                circular.append(cycle)
                return
            
            if node in visited:
                return
            
            visited.add(node)
            rec_stack.add(node)
            
            for neighbor in import_graph.get(node, []):
                if neighbor in import_graph:  # ë‚´ë¶€ íŒŒì¼ë§Œ
                    dfs(neighbor, path + [node])
            
            rec_stack.remove(node)
        
        for file in import_graph:
            if file not in visited:
                dfs(file, [])
        
        return circular
    
    def _check_missing_imports(self, import_graph: Dict[str, Set[str]]) -> List[Dict[str, str]]:
        """ëˆ„ë½ëœ ì„í¬íŠ¸ ê²€ì‚¬"""
        missing = []
        
        for file_path, imports in import_graph.items():
            for imp in imports:
                try:
                    if not imp.startswith('.'):
                        importlib.import_module(imp)
                except ImportError as e:
                    missing.append({
                        'file': file_path,
                        'import': imp,
                        'error': str(e)
                    })
        
        return missing
    
    def _generate_import_optimizations(self, analysis: Dict[str, Any]) -> List[str]:
        """ì„í¬íŠ¸ ìµœì í™” ì œì•ˆ"""
        suggestions = []
        
        # ì¤‘ë³µëœ ì™¸ë¶€ ì˜ì¡´ì„±
        ext_deps = analysis['external_dependencies']
        if len(ext_deps) > 50:
            suggestions.append(f"ì™¸ë¶€ ì˜ì¡´ì„±ì´ {len(ext_deps)}ê°œë¡œ ë§ìŠµë‹ˆë‹¤. í•„ìˆ˜ì ì¸ ê²ƒë§Œ ë‚¨ê¸°ê³  ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        # ìˆœí™˜ ì„í¬íŠ¸
        if analysis['circular_imports']:
            suggestions.append(f"ìˆœí™˜ ì„í¬íŠ¸ {len(analysis['circular_imports'])}ê°œ ë°œê²¬. êµ¬ì¡° ì¬ì„¤ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ëˆ„ë½ëœ ì„í¬íŠ¸
        if analysis['missing_imports']:
            suggestions.append(f"ëˆ„ë½ëœ ì„í¬íŠ¸ {len(analysis['missing_imports'])}ê°œ ë°œê²¬. requirements.txt ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return suggestions
    
    def validate_debugging_system(self) -> Dict[str, Any]:
        """ë””ë²„ê¹… ì‹œìŠ¤í…œ ê²€ì¦"""
        logger.info("ğŸ› ë””ë²„ê¹… ì‹œìŠ¤í…œ ê²€ì¦ ì‹œì‘...")
        
        debug_validation = {
            'logging_setup': False,
            'error_handling': [],
            'trace_capabilities': False,
            'debug_endpoints': [],
            'log_levels': [],
            'debug_modes': [],
            'suggestions': []
        }
        
        # ë¡œê¹… ì„¤ì • í™•ì¸
        logging_files = list(self.root_path.rglob("*log*.py"))
        if logging_files:
            debug_validation['logging_setup'] = True
            debug_validation['suggestions'].append("âœ… ë¡œê¹… ì‹œìŠ¤í…œ íŒŒì¼ ë°œê²¬")
        
        # ì—ëŸ¬ í•¸ë“¤ë§ íŒ¨í„´ ê²€ì‚¬
        python_files = list(self.root_path.rglob("*.py"))
        error_patterns = ['try:', 'except:', 'raise', 'logger.error', 'logger.warning']
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                error_handling_count = sum(1 for pattern in error_patterns if pattern in content)
                if error_handling_count > 0:
                    debug_validation['error_handling'].append({
                        'file': str(py_file.relative_to(self.root_path)),
                        'error_handling_patterns': error_handling_count
                    })
            except:
                continue
        
        # ë””ë²„ê¹… ì œì•ˆ
        if len(debug_validation['error_handling']) < 5:
            debug_validation['suggestions'].append("âš ï¸ ì—ëŸ¬ í•¸ë“¤ë§ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. try-except ë¸”ë¡ì„ ë” ì¶”ê°€í•˜ì„¸ìš”.")
        
        return debug_validation
    
    def analyze_performance(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¶„ì„"""
        logger.info("âš¡ ì„±ëŠ¥ ë¶„ì„ ì‹œì‘...")
        
        performance_analysis = {
            'memory_usage': {},
            'cpu_usage': {},
            'async_patterns': [],
            'bottlenecks': [],
            'optimization_opportunities': [],
            'suggestions': []
        }
        
        # í˜„ì¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
        process = psutil.Process()
        performance_analysis['memory_usage'] = {
            'rss_mb': process.memory_info().rss / 1024 / 1024,
            'vms_mb': process.memory_info().vms / 1024 / 1024,
            'percent': process.memory_percent()
        }
        
        performance_analysis['cpu_usage'] = {
            'percent': process.cpu_percent(interval=1),
            'num_threads': process.num_threads()
        }
        
        # ë¹„ë™ê¸° íŒ¨í„´ ê²€ì‚¬
        python_files = list(self.root_path.rglob("*.py"))
        async_patterns = ['async def', 'await ', 'asyncio.', 'aiohttp']
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                async_count = sum(1 for pattern in async_patterns if pattern in content)
                if async_count > 0:
                    performance_analysis['async_patterns'].append({
                        'file': str(py_file.relative_to(self.root_path)),
                        'async_patterns': async_count
                    })
            except:
                continue
        
        # ìµœì í™” ì œì•ˆ
        if performance_analysis['memory_usage']['rss_mb'] > 500:
            performance_analysis['suggestions'].append("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        if len(performance_analysis['async_patterns']) < 3:
            performance_analysis['suggestions'].append("ğŸ’¡ ë¹„ë™ê¸° íŒ¨í„´ ì‚¬ìš©ì„ ëŠ˜ë ¤ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return performance_analysis
    
    async def validate_endpoints(self) -> Dict[str, Any]:
        """API ì—”ë“œí¬ì¸íŠ¸ ê²€ì¦"""
        logger.info("ğŸŒ API ì—”ë“œí¬ì¸íŠ¸ ê²€ì¦ ì‹œì‘...")
        
        endpoint_validation = {
            'api_files': [],
            'endpoints_found': [],
            'health_checks': [],
            'security_headers': [],
            'response_times': {},
            'status_codes': {},
            'suggestions': []
        }
        
        # API ê´€ë ¨ íŒŒì¼ ì°¾ê¸°
        api_patterns = ['router', 'api', 'endpoint', 'server']
        api_files = []
        
        for pattern in api_patterns:
            api_files.extend(list(self.root_path.rglob(f"*{pattern}*.py")))
        
        endpoint_validation['api_files'] = [str(f.relative_to(self.root_path)) for f in api_files]
        
        # ì—”ë“œí¬ì¸íŠ¸ íŒ¨í„´ ê²€ì‚¬
        endpoint_patterns = ['@app.', '@router.', 'app.get', 'app.post', 'FastAPI']
        
        for api_file in api_files:
            try:
                with open(api_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                endpoints = []
                for pattern in endpoint_patterns:
                    if pattern in content:
                        endpoints.append(pattern)
                
                if endpoints:
                    endpoint_validation['endpoints_found'].append({
                        'file': str(api_file.relative_to(self.root_path)),
                        'patterns': endpoints
                    })
            except:
                continue
        
        # ë¡œì»¬ API í…ŒìŠ¤íŠ¸ (í¬íŠ¸ 8004)
        test_urls = [
            'http://localhost:8004/health',
            'http://localhost:8004/api/status',
            'http://localhost:8004/api/positions'
        ]
        
        for url in test_urls:
            try:
                start_time = time.time()
                response = requests.get(url, timeout=5)
                response_time = time.time() - start_time
                
                endpoint_validation['response_times'][url] = response_time
                endpoint_validation['status_codes'][url] = response.status_code
                
                if response.status_code == 200:
                    endpoint_validation['health_checks'].append(f"âœ… {url}")
                else:
                    endpoint_validation['health_checks'].append(f"âš ï¸ {url} - Status: {response.status_code}")
                    
            except Exception as e:
                endpoint_validation['health_checks'].append(f"âŒ {url} - Error: {str(e)}")
        
        # ì œì•ˆì‚¬í•­
        if not endpoint_validation['endpoints_found']:
            endpoint_validation['suggestions'].append("âš ï¸ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if not endpoint_validation['health_checks']:
            endpoint_validation['suggestions'].append("ğŸ’¡ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        return endpoint_validation
    
    def validate_error_handling(self) -> Dict[str, Any]:
        """ì—ëŸ¬ í•¸ë“¤ë§ ê²€ì¦"""
        logger.info("ğŸš¨ ì—ëŸ¬ í•¸ë“¤ë§ ê²€ì¦ ì‹œì‘...")
        
        error_validation = {
            'try_catch_blocks': 0,
            'error_types_handled': set(),
            'logging_in_errors': 0,
            'recovery_mechanisms': [],
            'error_propagation': [],
            'suggestions': []
        }
        
        python_files = list(self.root_path.rglob("*.py"))
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # try-except ë¸”ë¡ ê°œìˆ˜
                error_validation['try_catch_blocks'] += content.count('try:')
                
                # ë¡œê¹…ì´ ìˆëŠ” ì—ëŸ¬ ì²˜ë¦¬
                if 'except' in content and 'logger' in content:
                    error_validation['logging_in_errors'] += content.count('logger.error')
                
                # ì—ëŸ¬ íƒ€ì… ì¶”ì¶œ
                lines = content.split('\n')
                for line in lines:
                    if 'except ' in line and ':' in line:
                        # except Exception as e: ê°™ì€ íŒ¨í„´ ì¶”ì¶œ
                        try:
                            error_type = line.split('except ')[1].split(' as')[0].split(':')[0].strip()
                            if error_type and error_type != 'Exception':
                                error_validation['error_types_handled'].add(error_type)
                        except:
                            continue
                            
            except Exception as e:
                logger.error(f"ì—ëŸ¬ í•¸ë“¤ë§ ë¶„ì„ ì‹¤íŒ¨ {py_file}: {e}")
        
        # ì œì•ˆì‚¬í•­
        if error_validation['try_catch_blocks'] < 10:
            error_validation['suggestions'].append("âš ï¸ try-except ë¸”ë¡ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë” ë§ì€ ì—ëŸ¬ ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if error_validation['logging_in_errors'] < 5:
            error_validation['suggestions'].append("ğŸ’¡ ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê¹…ì„ ì¶”ê°€í•˜ì—¬ ë””ë²„ê¹…ì„ ê°œì„ í•˜ì„¸ìš”.")
        
        if len(error_validation['error_types_handled']) < 5:
            error_validation['suggestions'].append("ğŸ’¡ êµ¬ì²´ì ì¸ ì˜ˆì™¸ íƒ€ì…ì„ ë” ë§ì´ ì²˜ë¦¬í•˜ì„¸ìš”.")
        
        # setì„ listë¡œ ë³€í™˜
        error_validation['error_types_handled'] = list(error_validation['error_types_handled'])
        
        return error_validation
    
    def validate_security(self) -> Dict[str, Any]:
        """ë³´ì•ˆ ê²€ì¦"""
        logger.info("ğŸ”’ ë³´ì•ˆ ê²€ì¦ ì‹œì‘...")
        
        security_validation = {
            'api_key_exposure': [],
            'hardcoded_secrets': [],
            'input_validation': [],
            'authentication_methods': [],
            'encryption_usage': [],
            'security_headers': [],
            'suggestions': []
        }
        
        python_files = list(self.root_path.rglob("*.py"))
        sensitive_patterns = [
            'api_key', 'secret', 'password', 'token', 'private_key'
        ]
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ë¯¼ê° ì •ë³´ ë…¸ì¶œ ê²€ì‚¬
                for pattern in sensitive_patterns:
                    if f'{pattern} = ' in content.lower() and 'os.getenv' not in content.lower():
                        security_validation['hardcoded_secrets'].append({
                            'file': str(py_file.relative_to(self.root_path)),
                            'pattern': pattern
                        })
                
                # ì…ë ¥ ê²€ì¦ íŒ¨í„´
                validation_patterns = ['validate', 'sanitize', 'escape', 'filter']
                for pattern in validation_patterns:
                    if pattern in content.lower():
                        security_validation['input_validation'].append({
                            'file': str(py_file.relative_to(self.root_path)),
                            'pattern': pattern
                        })
                
                # ì¸ì¦ ë©”ì„œë“œ
                auth_patterns = ['authenticate', 'authorize', 'jwt', 'oauth', 'login']
                for pattern in auth_patterns:
                    if pattern in content.lower():
                        security_validation['authentication_methods'].append({
                            'file': str(py_file.relative_to(self.root_path)),
                            'pattern': pattern
                        })
                        
            except Exception as e:
                logger.error(f"ë³´ì•ˆ ë¶„ì„ ì‹¤íŒ¨ {py_file}: {e}")
        
        # ì œì•ˆì‚¬í•­
        if security_validation['hardcoded_secrets']:
            security_validation['suggestions'].append("ğŸš¨ í•˜ë“œì½”ë”©ëœ ë¹„ë°€ ì •ë³´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        if not security_validation['input_validation']:
            security_validation['suggestions'].append("âš ï¸ ì…ë ¥ ê²€ì¦ ë¡œì§ì„ ì¶”ê°€í•˜ì„¸ìš”.")
        
        if not security_validation['authentication_methods']:
            security_validation['suggestions'].append("ğŸ’¡ ì¸ì¦ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•˜ì„¸ìš”.")
        
        return security_validation
    
    def generate_requirements_txt(self) -> Dict[str, Any]:
        """requirements.txt ìƒì„± ë° ê²€ì¦"""
        logger.info("ğŸ“¦ Requirements ë¶„ì„ ì‹œì‘...")
        
        requirements_analysis = {
            'current_requirements': [],
            'detected_imports': set(),
            'missing_packages': [],
            'unused_packages': [],
            'version_conflicts': [],
            'suggestions': []
        }
        
        # í˜„ì¬ requirements.txt ì½ê¸°
        req_file = self.root_path / 'requirements.txt'
        if req_file.exists():
            with open(req_file, 'r') as f:
                requirements_analysis['current_requirements'] = [line.strip() for line in f if line.strip() and not line.startswith('#')]
        
        # ì½”ë“œì—ì„œ ì„í¬íŠ¸ ì¶”ì¶œ
        python_files = list(self.root_path.rglob("*.py"))
        common_packages = {
            'ccxt': 'ccxt',
            'pandas': 'pandas',
            'numpy': 'numpy',
            'aiohttp': 'aiohttp',
            'asyncio': '',  # ë‚´ì¥ ëª¨ë“ˆ
            'requests': 'requests',
            'psutil': 'psutil',
            'fastapi': 'fastapi',
            'uvicorn': 'uvicorn',
            'redis': 'redis',
            'sqlalchemy': 'sqlalchemy',
            'python-dotenv': 'python-dotenv'
        }
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                imports = self._extract_imports(tree)
                
                for imp in imports:
                    if imp in common_packages and common_packages[imp]:
                        requirements_analysis['detected_imports'].add(common_packages[imp])
                        
            except:
                continue
        
        # ëˆ„ë½ëœ íŒ¨í‚¤ì§€ í™•ì¸
        current_packages = {req.split('==')[0].split('>=')[0].split('<=')[0] for req in requirements_analysis['current_requirements']}
        for detected in requirements_analysis['detected_imports']:
            if detected not in current_packages:
                requirements_analysis['missing_packages'].append(detected)
        
        # ì œì•ˆì‚¬í•­
        if requirements_analysis['missing_packages']:
            requirements_analysis['suggestions'].append(f"ğŸ“¦ ëˆ„ë½ëœ íŒ¨í‚¤ì§€ {len(requirements_analysis['missing_packages'])}ê°œë¥¼ requirements.txtì— ì¶”ê°€í•˜ì„¸ìš”.")
        
        requirements_analysis['detected_imports'] = list(requirements_analysis['detected_imports'])
        
        return requirements_analysis
    
    async def run_comprehensive_validation(self) -> Dict[str, Any]:
        """ì¢…í•© ê²€ì¦ ì‹¤í–‰"""
        logger.info("ğŸš€ VPS Deployment ì¢…í•© ê²€ì¦ ì‹œì‘...")
        
        start_time = time.time()
        
        # 1. ì„í¬íŠ¸ ë¶„ì„
        self.results['validation_results']['import_analysis'] = self.analyze_imports()
        
        # 2. ë””ë²„ê¹… ì‹œìŠ¤í…œ
        self.results['validation_results']['debugging_system'] = self.validate_debugging_system()
        
        # 3. ì„±ëŠ¥ ë¶„ì„
        self.results['validation_results']['performance_analysis'] = self.analyze_performance()
        
        # 4. ì—”ë“œí¬ì¸íŠ¸ ê²€ì¦
        self.results['validation_results']['endpoint_validation'] = await self.validate_endpoints()
        
        # 5. ì—ëŸ¬ í•¸ë“¤ë§
        self.results['validation_results']['error_handling'] = self.validate_error_handling()
        
        # 6. ë³´ì•ˆ ê²€ì¦
        self.results['validation_results']['security_validation'] = self.validate_security()
        
        # 7. Requirements ë¶„ì„
        self.results['validation_results']['requirements_analysis'] = self.generate_requirements_txt()
        
        # ì‹¤í–‰ ì‹œê°„
        self.results['execution_time_seconds'] = time.time() - start_time
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        self.results['overall_score'] = self._calculate_overall_score()
        
        return self.results
    
    def _calculate_overall_score(self) -> Dict[str, Any]:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        scores = {
            'import_health': 0,
            'debugging_readiness': 0,
            'performance_efficiency': 0,
            'api_reliability': 0,
            'error_resilience': 0,
            'security_strength': 0,
            'overall_rating': 'F'
        }
        
        # ì„í¬íŠ¸ ê±´ì „ì„± (20ì )
        import_result = self.results['validation_results']['import_analysis']
        if not import_result['circular_imports']:
            scores['import_health'] += 10
        if len(import_result['missing_imports']) < 3:
            scores['import_health'] += 10
        
        # ë””ë²„ê¹… ì¤€ë¹„ë„ (15ì )
        debug_result = self.results['validation_results']['debugging_system']
        if debug_result['logging_setup']:
            scores['debugging_readiness'] += 8
        if len(debug_result['error_handling']) > 5:
            scores['debugging_readiness'] += 7
        
        # ì„±ëŠ¥ íš¨ìœ¨ì„± (15ì )
        perf_result = self.results['validation_results']['performance_analysis']
        if perf_result['memory_usage']['rss_mb'] < 300:
            scores['performance_efficiency'] += 8
        if len(perf_result['async_patterns']) > 3:
            scores['performance_efficiency'] += 7
        
        # API ì‹ ë¢°ì„± (15ì )
        api_result = self.results['validation_results']['endpoint_validation']
        if len(api_result['endpoints_found']) > 0:
            scores['api_reliability'] += 8
        if len(api_result['health_checks']) > 0:
            scores['api_reliability'] += 7
        
        # ì—ëŸ¬ ë³µì›ë ¥ (20ì )
        error_result = self.results['validation_results']['error_handling']
        if error_result['try_catch_blocks'] > 10:
            scores['error_resilience'] += 10
        if error_result['logging_in_errors'] > 5:
            scores['error_resilience'] += 10
        
        # ë³´ì•ˆ ê°•ë„ (15ì )
        security_result = self.results['validation_results']['security_validation']
        if not security_result['hardcoded_secrets']:
            scores['security_strength'] += 8
        if len(security_result['input_validation']) > 0:
            scores['security_strength'] += 7
        
        # ì „ì²´ ì ìˆ˜ (100ì  ë§Œì )
        total_score = sum(scores.values())
        
        if total_score >= 90:
            scores['overall_rating'] = 'A+'
        elif total_score >= 80:
            scores['overall_rating'] = 'A'
        elif total_score >= 70:
            scores['overall_rating'] = 'B'
        elif total_score >= 60:
            scores['overall_rating'] = 'C'
        elif total_score >= 50:
            scores['overall_rating'] = 'D'
        else:
            scores['overall_rating'] = 'F'
        
        scores['total_score'] = total_score
        
        return scores
    
    def generate_report(self) -> str:
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("ğŸ” VPS DEPLOYMENT ì‹œìŠ¤í…œ ê²€ì¦ ë¦¬í¬íŠ¸")
        report_lines.append("=" * 60)
        report_lines.append(f"ê²€ì¦ ì‹œê°„: {self.results['timestamp']}")
        report_lines.append(f"ì‹¤í–‰ ì‹œê°„: {self.results['execution_time_seconds']:.2f}ì´ˆ")
        report_lines.append("")
        
        # ì¢…í•© ì ìˆ˜
        score = self.results['overall_score']
        report_lines.append(f"ğŸ“Š ì¢…í•© ì ìˆ˜: {score['total_score']}/100 ({score['overall_rating']})")
        report_lines.append("")
        
        # ê° ì˜ì—­ë³„ ê²°ê³¼
        results = self.results['validation_results']
        
        # 1. ì„í¬íŠ¸ ë¶„ì„
        import_result = results['import_analysis']
        report_lines.append("1. ğŸ“¦ ì„í¬íŠ¸ ë¶„ì„")
        report_lines.append(f"   - Python íŒŒì¼: {len(import_result['python_files'])}ê°œ")
        report_lines.append(f"   - ì™¸ë¶€ ì˜ì¡´ì„±: {len(import_result['external_dependencies'])}ê°œ")
        report_lines.append(f"   - ë‚´ë¶€ ì˜ì¡´ì„±: {len(import_result['internal_dependencies'])}ê°œ")
        report_lines.append(f"   - ìˆœí™˜ ì„í¬íŠ¸: {len(import_result['circular_imports'])}ê°œ")
        report_lines.append(f"   - ëˆ„ë½ëœ ì„í¬íŠ¸: {len(import_result['missing_imports'])}ê°œ")
        report_lines.append("")
        
        # 2. ë””ë²„ê¹… ì‹œìŠ¤í…œ
        debug_result = results['debugging_system']
        report_lines.append("2. ğŸ› ë””ë²„ê¹… ì‹œìŠ¤í…œ")
        report_lines.append(f"   - ë¡œê¹… ì„¤ì •: {'âœ…' if debug_result['logging_setup'] else 'âŒ'}")
        report_lines.append(f"   - ì—ëŸ¬ í•¸ë“¤ë§ íŒŒì¼: {len(debug_result['error_handling'])}ê°œ")
        report_lines.append("")
        
        # 3. ì„±ëŠ¥ ë¶„ì„
        perf_result = results['performance_analysis']
        report_lines.append("3. âš¡ ì„±ëŠ¥ ë¶„ì„")
        report_lines.append(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {perf_result['memory_usage']['rss_mb']:.1f}MB")
        report_lines.append(f"   - CPU ì‚¬ìš©ë¥ : {perf_result['cpu_usage']['percent']:.1f}%")
        report_lines.append(f"   - ë¹„ë™ê¸° íŒ¨í„´: {len(perf_result['async_patterns'])}ê°œ íŒŒì¼")
        report_lines.append("")
        
        # 4. API ê²€ì¦
        api_result = results['endpoint_validation']
        report_lines.append("4. ğŸŒ API ì—”ë“œí¬ì¸íŠ¸")
        report_lines.append(f"   - API íŒŒì¼: {len(api_result['api_files'])}ê°œ")
        report_lines.append(f"   - ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬: {len(api_result['endpoints_found'])}ê°œ")
        report_lines.append(f"   - í—¬ìŠ¤ì²´í¬: {len(api_result['health_checks'])}ê°œ")
        report_lines.append("")
        
        # 5. ì—ëŸ¬ í•¸ë“¤ë§
        error_result = results['error_handling']
        report_lines.append("5. ğŸš¨ ì—ëŸ¬ í•¸ë“¤ë§")
        report_lines.append(f"   - Try-Catch ë¸”ë¡: {error_result['try_catch_blocks']}ê°œ")
        report_lines.append(f"   - ì—ëŸ¬ ë¡œê¹…: {error_result['logging_in_errors']}ê°œ")
        report_lines.append(f"   - ì²˜ë¦¬í•˜ëŠ” ì—ëŸ¬ íƒ€ì…: {len(error_result['error_types_handled'])}ê°œ")
        report_lines.append("")
        
        # 6. ë³´ì•ˆ ê²€ì¦
        security_result = results['security_validation']
        report_lines.append("6. ğŸ”’ ë³´ì•ˆ ê²€ì¦")
        report_lines.append(f"   - í•˜ë“œì½”ë”©ëœ ë¹„ë°€ì •ë³´: {len(security_result['hardcoded_secrets'])}ê°œ")
        report_lines.append(f"   - ì…ë ¥ ê²€ì¦: {len(security_result['input_validation'])}ê°œ")
        report_lines.append(f"   - ì¸ì¦ ë©”ì„œë“œ: {len(security_result['authentication_methods'])}ê°œ")
        report_lines.append("")
        
        # ì œì•ˆì‚¬í•­
        report_lines.append("ğŸ’¡ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        all_suggestions = []
        for category, result in results.items():
            if 'suggestions' in result:
                all_suggestions.extend(result['suggestions'])
        
        for i, suggestion in enumerate(all_suggestions[:10], 1):  # ìƒìœ„ 10ê°œë§Œ
            report_lines.append(f"   {i}. {suggestion}")
        
        report_lines.append("")
        report_lines.append("=" * 60)
        
        return "\n".join(report_lines)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    validator = SystemValidator()
    
    print("ğŸš€ VPS Deployment ì‹œìŠ¤í…œ ì¢…í•© ê²€ì¦ ì‹œì‘...")
    print("ì´ ì‘ì—…ì€ ëª‡ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...\n")
    
    try:
        # ì¢…í•© ê²€ì¦ ì‹¤í–‰
        results = await validator.run_comprehensive_validation()
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = validator.generate_report()
        print(report)
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        with open('system_validation_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        with open('system_validation_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“„ ìƒì„¸ ê²°ê³¼ê°€ ë‹¤ìŒ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"   - system_validation_results.json")
        print(f"   - system_validation_report.txt")
        
    except Exception as e:
        logger.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())