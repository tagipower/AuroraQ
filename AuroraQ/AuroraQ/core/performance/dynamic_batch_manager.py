#!/usr/bin/env python3
"""
ë™ì  ë°°ì¹˜ í¬ê¸° ê´€ë¦¬ì
P1-3: ì„±ëŠ¥ íŠœë‹ - ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ë™ì  ì¡°ì •
"""

import psutil
import time
import logging
from typing import Dict, Any, Optional, Tuple, List
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import asyncio
import gc
from enum import Enum

logger = logging.getLogger(__name__)

class ResourceState(Enum):
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìƒíƒœ"""
    OPTIMAL = "optimal"
    STRESSED = "stressed"
    CRITICAL = "critical"
    RECOVERING = "recovering"

@dataclass
class BatchConfig:
    """ë°°ì¹˜ ì„¤ì •"""
    initial_batch_size: int = 64
    min_batch_size: int = 8
    max_batch_size: int = 256
    target_memory_mb: float = 1500.0
    max_memory_mb: float = 2500.0
    target_cpu_percent: float = 70.0
    max_cpu_percent: float = 85.0
    target_processing_time_s: float = 2.0
    max_processing_time_s: float = 5.0
    adjustment_factor: float = 0.15  # 15% ì¡°ì •

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    memory_usage_mb: float = 0.0
    cpu_percent: float = 0.0
    processing_time_s: float = 0.0
    items_processed: int = 0
    success_rate: float = 1.0
    timestamp: datetime = field(default_factory=datetime.now)

class DynamicBatchManager:
    """ë™ì  ë°°ì¹˜ í¬ê¸° ê´€ë¦¬ì"""
    
    def __init__(self, config: BatchConfig = None):
        self.config = config or BatchConfig()
        self.current_batch_size = self.config.initial_batch_size
        self.current_state = ResourceState.OPTIMAL
        
        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬
        self.metrics_history = []
        self.max_history_size = 100
        
        # ì¡°ì • í†µê³„
        self.adjustment_stats = {
            "total_adjustments": 0,
            "increases": 0,
            "decreases": 0,
            "last_adjustment": None,
            "state_transitions": 0
        }
        
        # ì•ˆì •ì„± ì œì–´
        self.last_adjustment_time = 0
        self.min_adjustment_interval_s = 5.0  # ìµœì†Œ 5ì´ˆ ê°„ê²©
        self.consecutive_good_batches = 0
        self.consecutive_bad_batches = 0
        
        logger.info(f"Dynamic batch manager initialized: initial={self.current_batch_size}, "
                   f"range=({self.config.min_batch_size}-{self.config.max_batch_size})")
    
    def get_current_batch_size(self) -> int:
        """í˜„ì¬ ë°°ì¹˜ í¬ê¸° ë°˜í™˜"""
        return self.current_batch_size
    
    def collect_system_metrics(self) -> PerformanceMetrics:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory_info = psutil.virtual_memory()
            memory_used_mb = (memory_info.total - memory_info.available) / 1024 / 1024
            
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            metrics = PerformanceMetrics(
                memory_usage_mb=memory_used_mb,
                cpu_percent=cpu_percent,
                timestamp=datetime.now()
            )
            
            return metrics
            
        except Exception as e:
            logger.warning(f"Failed to collect system metrics: {e}")
            return PerformanceMetrics()
    
    def update_batch_performance(self, processing_time: float, items_processed: int, 
                               success_rate: float = 1.0, custom_metrics: Dict[str, Any] = None):
        """ë°°ì¹˜ ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        try:
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            system_metrics = self.collect_system_metrics()
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìƒì„±
            metrics = PerformanceMetrics(
                memory_usage_mb=system_metrics.memory_usage_mb,
                cpu_percent=system_metrics.cpu_percent,
                processing_time_s=processing_time,
                items_processed=items_processed,
                success_rate=success_rate
            )
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.metrics_history.append(metrics)
            if len(self.metrics_history) > self.max_history_size:
                self.metrics_history.pop(0)
            
            # ë¦¬ì†ŒìŠ¤ ìƒíƒœ í‰ê°€
            new_state = self._evaluate_resource_state(metrics)
            if new_state != self.current_state:
                logger.info(f"Resource state changed: {self.current_state.value} -> {new_state.value}")
                self.current_state = new_state
                self.adjustment_stats["state_transitions"] += 1
            
            # ë°°ì¹˜ í¬ê¸° ì¡°ì •
            self._adjust_batch_size(metrics)
            
            logger.debug(f"Batch performance updated: size={self.current_batch_size}, "
                        f"time={processing_time:.2f}s, items={items_processed}, "
                        f"memory={metrics.memory_usage_mb:.1f}MB, cpu={metrics.cpu_percent:.1f}%")
            
        except Exception as e:
            logger.error(f"Failed to update batch performance: {e}")
    
    def _evaluate_resource_state(self, metrics: PerformanceMetrics) -> ResourceState:
        """ë¦¬ì†ŒìŠ¤ ìƒíƒœ í‰ê°€"""
        
        # Critical ìƒíƒœ ê²€ì‚¬
        if (metrics.memory_usage_mb > self.config.max_memory_mb or
            metrics.cpu_percent > self.config.max_cpu_percent or
            metrics.processing_time_s > self.config.max_processing_time_s):
            return ResourceState.CRITICAL
        
        # Stressed ìƒíƒœ ê²€ì‚¬
        stress_score = 0
        if metrics.memory_usage_mb > self.config.target_memory_mb:
            stress_score += 1
        if metrics.cpu_percent > self.config.target_cpu_percent:
            stress_score += 1
        if metrics.processing_time_s > self.config.target_processing_time_s:
            stress_score += 1
        
        if stress_score >= 2:
            return ResourceState.STRESSED
        
        # Recovering ìƒíƒœ ê²€ì‚¬ (ì´ì „ ìƒíƒœê°€ CRITICAL/STRESSEDì´ê³  í˜„ì¬ ê°œì„ ë¨)
        if (self.current_state in [ResourceState.CRITICAL, ResourceState.STRESSED] and
            stress_score <= 1):
            return ResourceState.RECOVERING
        
        return ResourceState.OPTIMAL
    
    def _adjust_batch_size(self, metrics: PerformanceMetrics):
        """ë°°ì¹˜ í¬ê¸° ì¡°ì •"""
        current_time = time.time()
        
        # ìµœì†Œ ê°„ê²© ì²´í¬
        if current_time - self.last_adjustment_time < self.min_adjustment_interval_s:
            return
        
        old_size = self.current_batch_size
        adjustment_made = False
        
        # ìƒíƒœë³„ ì¡°ì • ì „ëµ
        if self.current_state == ResourceState.CRITICAL:
            # ì¦‰ì‹œ í° í­ìœ¼ë¡œ ê°ì†Œ
            reduction = max(8, int(self.current_batch_size * 0.3))
            self.current_batch_size = max(self.config.min_batch_size, 
                                        self.current_batch_size - reduction)
            adjustment_made = True
            self.consecutive_bad_batches += 1
            self.consecutive_good_batches = 0
            
        elif self.current_state == ResourceState.STRESSED:
            # ì¤‘ê°„ í­ìœ¼ë¡œ ê°ì†Œ
            reduction = max(2, int(self.current_batch_size * self.config.adjustment_factor))
            self.current_batch_size = max(self.config.min_batch_size,
                                        self.current_batch_size - reduction)
            adjustment_made = True
            self.consecutive_bad_batches += 1
            self.consecutive_good_batches = 0
            
        elif self.current_state == ResourceState.OPTIMAL:
            # ì•ˆì •ì ìœ¼ë¡œ ì¦ê°€
            self.consecutive_good_batches += 1
            self.consecutive_bad_batches = 0
            
            # ì—°ì†ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì´ë©´ ì¦ê°€
            if self.consecutive_good_batches >= 3:
                increase = max(1, int(self.current_batch_size * (self.config.adjustment_factor / 2)))
                self.current_batch_size = min(self.config.max_batch_size,
                                            self.current_batch_size + increase)
                adjustment_made = True
                self.consecutive_good_batches = 0
                
        elif self.current_state == ResourceState.RECOVERING:
            # íšŒë³µ ì¤‘ì´ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ ì¡°ì •
            self.consecutive_good_batches += 1
            if self.consecutive_good_batches >= 5:  # ë” ì˜¤ë˜ ê¸°ë‹¤ë¦¼
                increase = 1  # ì•„ì£¼ ì‘ê²Œ ì¦ê°€
                self.current_batch_size = min(self.config.max_batch_size,
                                            self.current_batch_size + increase)
                adjustment_made = True
                self.consecutive_good_batches = 0
        
        # ì¡°ì • í†µê³„ ì—…ë°ì´íŠ¸
        if adjustment_made:
            self.last_adjustment_time = current_time
            self.adjustment_stats["total_adjustments"] += 1
            self.adjustment_stats["last_adjustment"] = datetime.now().isoformat()
            
            if self.current_batch_size > old_size:
                self.adjustment_stats["increases"] += 1
                logger.info(f"Batch size increased: {old_size} -> {self.current_batch_size} "
                           f"(state: {self.current_state.value})")
            elif self.current_batch_size < old_size:
                self.adjustment_stats["decreases"] += 1
                logger.info(f"Batch size decreased: {old_size} -> {self.current_batch_size} "
                           f"(state: {self.current_state.value})")
    
    def force_batch_size(self, size: int, reason: str = "manual"):
        """ë°°ì¹˜ í¬ê¸° ê°•ì œ ì„¤ì •"""
        old_size = self.current_batch_size
        self.current_batch_size = max(self.config.min_batch_size, 
                                    min(self.config.max_batch_size, size))
        
        logger.info(f"Batch size forced: {old_size} -> {self.current_batch_size} (reason: {reason})")
        self.adjustment_stats["total_adjustments"] += 1
        self.adjustment_stats["last_adjustment"] = datetime.now().isoformat()
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜"""
        if not self.metrics_history:
            return {"status": "no_data"}
        
        recent_metrics = self.metrics_history[-10:]  # ìµœê·¼ 10ê°œ
        
        avg_memory = sum(m.memory_usage_mb for m in recent_metrics) / len(recent_metrics)
        avg_cpu = sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics)
        avg_time = sum(m.processing_time_s for m in recent_metrics) / len(recent_metrics)
        avg_success_rate = sum(m.success_rate for m in recent_metrics) / len(recent_metrics)
        
        return {
            "current_batch_size": self.current_batch_size,
            "current_state": self.current_state.value,
            "performance": {
                "avg_memory_mb": round(avg_memory, 1),
                "avg_cpu_percent": round(avg_cpu, 1),
                "avg_processing_time_s": round(avg_time, 2),
                "avg_success_rate": round(avg_success_rate, 3)
            },
            "config": {
                "min_batch_size": self.config.min_batch_size,
                "max_batch_size": self.config.max_batch_size,
                "target_memory_mb": self.config.target_memory_mb,
                "target_cpu_percent": self.config.target_cpu_percent
            },
            "adjustment_stats": self.adjustment_stats.copy(),
            "consecutive_good_batches": self.consecutive_good_batches,
            "consecutive_bad_batches": self.consecutive_bad_batches,
            "metrics_count": len(self.metrics_history)
        }
    
    def get_optimization_recommendations(self) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ë°˜í™˜"""
        recommendations = []
        
        if not self.metrics_history:
            return ["ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ê¶Œì¥ì‚¬í•­ì€ ë‚˜ì¤‘ì— ì œê³µë©ë‹ˆë‹¤."]
        
        summary = self.get_performance_summary()
        perf = summary["performance"]
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if perf["avg_memory_mb"] > self.config.max_memory_mb:
            recommendations.append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤ ({perf['avg_memory_mb']:.1f}MB). "
                                 f"ìµœëŒ€ ë°°ì¹˜ í¬ê¸°ë¥¼ {self.config.max_batch_size // 2}ë¡œ ë‚®ì¶°ë³´ì„¸ìš”.")
        
        # CPU ê¸°ë°˜ ê¶Œì¥ì‚¬í•­  
        if perf["avg_cpu_percent"] > self.config.max_cpu_percent:
            recommendations.append(f"CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({perf['avg_cpu_percent']:.1f}%). "
                                 f"ì²˜ë¦¬ ê°„ê²©ì„ ëŠ˜ë¦¬ê±°ë‚˜ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
        
        # ì²˜ë¦¬ ì‹œê°„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if perf["avg_processing_time_s"] > self.config.max_processing_time_s:
            recommendations.append(f"ì²˜ë¦¬ ì‹œê°„ì´ ê¹ë‹ˆë‹¤ ({perf['avg_processing_time_s']:.2f}s). "
                                 f"ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ì•Œê³ ë¦¬ì¦˜ì„ ìµœì í™”í•˜ì„¸ìš”.")
        
        # ì„±ê³µë¥  ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if perf["avg_success_rate"] < 0.95:
            recommendations.append(f"ì„±ê³µë¥ ì´ ë‚®ìŠµë‹ˆë‹¤ ({perf['avg_success_rate']:.1%}). "
                                 f"ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ì„ ì ê²€í•˜ì„¸ìš”.")
        
        # ì¡°ì • ë¹ˆë„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        total_adjustments = self.adjustment_stats["total_adjustments"]
        if total_adjustments > 20:
            decrease_ratio = self.adjustment_stats["decreases"] / total_adjustments
            if decrease_ratio > 0.7:
                recommendations.append("ë°°ì¹˜ í¬ê¸°ê°€ ìì£¼ ê°ì†Œí•©ë‹ˆë‹¤. ì´ˆê¸° ë°°ì¹˜ í¬ê¸°ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("í˜„ì¬ ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. ê³„ì† ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.")
        
        return recommendations
    
    async def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            memory_info = psutil.virtual_memory()
            memory_used_mb = (memory_info.total - memory_info.available) / 1024 / 1024
            
            logger.info(f"Resource cleanup completed. Memory usage: {memory_used_mb:.1f}MB")
            
        except Exception as e:
            logger.error(f"Resource cleanup failed: {e}")

# ì „ì—­ ë°°ì¹˜ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
_global_batch_manager = None

def get_batch_manager(config: BatchConfig = None) -> DynamicBatchManager:
    """ì „ì—­ ë°°ì¹˜ ê´€ë¦¬ì ë°˜í™˜"""
    global _global_batch_manager
    if _global_batch_manager is None:
        _global_batch_manager = DynamicBatchManager(config)
    return _global_batch_manager

# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import asyncio
    import random
    
    async def test_dynamic_batch_manager():
        print("ğŸ§ª Dynamic Batch Manager í…ŒìŠ¤íŠ¸")
        
        # ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ë§¤ë‹ˆì € ìƒì„±
        config = BatchConfig(
            initial_batch_size=32,
            min_batch_size=4,
            max_batch_size=128,
            target_memory_mb=1000.0,
            max_memory_mb=1500.0
        )
        
        manager = DynamicBatchManager(config)
        
        # ì‹œë®¬ë ˆì´ì…˜ëœ ë°°ì¹˜ ì²˜ë¦¬
        for i in range(20):
            # ëœë¤í•œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹œë®¬ë ˆì´ì…˜
            processing_time = random.uniform(0.5, 6.0)
            items_processed = manager.get_current_batch_size()
            success_rate = random.uniform(0.85, 1.0)
            
            print(f"\në°°ì¹˜ {i+1}: size={manager.get_current_batch_size()}, "
                  f"time={processing_time:.2f}s, items={items_processed}")
            
            # ì„±ëŠ¥ ì—…ë°ì´íŠ¸
            manager.update_batch_performance(processing_time, items_processed, success_rate)
            
            # ìš”ì•½ ì •ë³´
            if i % 5 == 4:  # 5ë²ˆë§ˆë‹¤ ìš”ì•½
                summary = manager.get_performance_summary()
                print(f"  ğŸ“Š ìƒíƒœ: {summary['current_state']}")
                print(f"  ğŸ“ˆ ì¡°ì • íšŸìˆ˜: {summary['adjustment_stats']['total_adjustments']}")
                
            await asyncio.sleep(0.1)
        
        # ìµœì¢… ìš”ì•½
        print("\nğŸ¯ ìµœì¢… ì„±ëŠ¥ ìš”ì•½:")
        summary = manager.get_performance_summary()
        print(f"  í˜„ì¬ ë°°ì¹˜ í¬ê¸°: {summary['current_batch_size']}")
        print(f"  í˜„ì¬ ìƒíƒœ: {summary['current_state']}")
        print(f"  í‰ê·  ë©”ëª¨ë¦¬: {summary['performance']['avg_memory_mb']:.1f}MB")
        print(f"  í‰ê·  CPU: {summary['performance']['avg_cpu_percent']:.1f}%")
        print(f"  ì´ ì¡°ì • íšŸìˆ˜: {summary['adjustment_stats']['total_adjustments']}")
        
        # ê¶Œì¥ì‚¬í•­
        print("\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
        recommendations = manager.get_optimization_recommendations()
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")
        
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        await manager.cleanup_resources()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_dynamic_batch_manager())