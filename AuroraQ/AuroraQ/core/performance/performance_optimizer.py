#!/usr/bin/env python3
"""
VPS Deployment ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ
ë©”ëª¨ë¦¬ ê´€ë¦¬, CPU ìµœì í™”, I/O ìµœì í™”, ìºì‹± ì „ëµ
"""

import asyncio
import gc
import json
import logging
import os
import psutil
import sys
import threading
import time
import weakref
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor
from contextlib import contextmanager
from datetime import datetime, timedelta
from functools import lru_cache, wraps
from typing import Any, Callable, Dict, List, Optional, Union
import resource


class MemoryManager:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, warning_threshold: float = 0.8, critical_threshold: float = 0.9):
        self.warning_threshold = warning_threshold
        self.critical_threshold = critical_threshold
        self.memory_limit_mb = 3072  # 3GB VPS ì œí•œ
        self.gc_stats = deque(maxlen=100)
        self.memory_snapshots = deque(maxlen=1000)
        self.large_objects = weakref.WeakSet()
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_memory, daemon=True)
        self.monitor_thread.start()
        
        self.logger = logging.getLogger(__name__)
    
    def _monitor_memory(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ"""
        while self.monitoring:
            try:
                usage = self.get_memory_usage()
                self.memory_snapshots.append({
                    'timestamp': time.time(),
                    'usage': usage
                })
                
                # ì„ê³„ì¹˜ í™•ì¸
                if usage['percent'] > self.critical_threshold:
                    self.emergency_cleanup()
                elif usage['percent'] > self.warning_threshold:
                    self.optimize_memory()
                
                time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
                
            except Exception as e:
                self.logger.error(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                time.sleep(60)
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰"""
        process = psutil.Process()
        memory_info = process.memory_info()
        vm_info = psutil.virtual_memory()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'percent': process.memory_percent(),
            'available_mb': vm_info.available / 1024 / 1024,
            'system_percent': vm_info.percent,
            'swap_mb': psutil.swap_memory().used / 1024 / 1024,
            'limit_mb': self.memory_limit_mb,
            'within_limit': memory_info.rss / 1024 / 1024 < self.memory_limit_mb
        }
    
    def optimize_memory(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        before_usage = self.get_memory_usage()
        
        # 1. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        collected = []
        for generation in range(3):
            collected.append(gc.collect(generation))
        
        # 2. í° ê°ì²´ ì •ë¦¬
        large_objects_count = len(self.large_objects)
        
        # 3. ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ (í•„ìš”ì‹œ)
        if hasattr(gc, 'freeze'):
            gc.freeze()
        
        after_usage = self.get_memory_usage()
        
        optimization_result = {
            'timestamp': datetime.now().isoformat(),
            'before_memory_mb': before_usage['rss_mb'],
            'after_memory_mb': after_usage['rss_mb'],
            'memory_freed_mb': before_usage['rss_mb'] - after_usage['rss_mb'],
            'gc_collected': sum(collected),
            'large_objects_tracked': large_objects_count,
            'optimization_type': 'routine'
        }
        
        self.gc_stats.append(optimization_result)
        self.logger.info(f"ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {optimization_result['memory_freed_mb']:.2f}MB í™•ë³´")
        
        return optimization_result
    
    def emergency_cleanup(self) -> Dict[str, Any]:
        """ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        self.logger.warning("ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘")
        
        before_usage = self.get_memory_usage()
        
        # 1. ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        collected = []
        for _ in range(3):  # ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰
            for generation in range(3):
                collected.append(gc.collect(generation))
        
        # 2. ë©”ëª¨ë¦¬ ë§¤í•‘ í•´ì œ
        if hasattr(resource, 'RLIMIT_DATA'):
            try:
                resource.setrlimit(resource.RLIMIT_DATA, (self.memory_limit_mb * 1024 * 1024, -1))
            except:
                pass
        
        # 3. ìºì‹œ ì •ë¦¬
        self._clear_all_caches()
        
        after_usage = self.get_memory_usage()
        
        cleanup_result = {
            'timestamp': datetime.now().isoformat(),
            'before_memory_mb': before_usage['rss_mb'],
            'after_memory_mb': after_usage['rss_mb'],
            'memory_freed_mb': before_usage['rss_mb'] - after_usage['rss_mb'],
            'gc_collected': sum(collected),
            'optimization_type': 'emergency'
        }
        
        self.gc_stats.append(cleanup_result)
        self.logger.warning(f"ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: {cleanup_result['memory_freed_mb']:.2f}MB í™•ë³´")
        
        return cleanup_result
    
    def _clear_all_caches(self):
        """ëª¨ë“  ìºì‹œ ì •ë¦¬"""
        # LRU ìºì‹œ ì •ë¦¬
        for obj in gc.get_objects():
            if hasattr(obj, 'cache_clear'):
                try:
                    obj.cache_clear()
                except:
                    pass
    
    def track_large_object(self, obj, threshold_mb: float = 10.0):
        """í° ê°ì²´ ì¶”ì """
        try:
            obj_size = sys.getsizeof(obj) / 1024 / 1024
            if obj_size > threshold_mb:
                self.large_objects.add(obj)
                self.logger.debug(f"í° ê°ì²´ ì¶”ì : {type(obj).__name__} ({obj_size:.2f}MB)")
        except:
            pass
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ í†µê³„"""
        if not self.memory_snapshots:
            return {"message": "No memory data available"}
        
        recent_snapshots = list(self.memory_snapshots)[-100:]  # ìµœê·¼ 100ê°œ
        memory_values = [s['usage']['rss_mb'] for s in recent_snapshots]
        
        return {
            'current_usage': self.get_memory_usage(),
            'avg_memory_mb': sum(memory_values) / len(memory_values),
            'max_memory_mb': max(memory_values),
            'min_memory_mb': min(memory_values),
            'gc_optimizations': len(self.gc_stats),
            'large_objects_tracked': len(self.large_objects),
            'recent_optimizations': list(self.gc_stats)[-5:] if self.gc_stats else []
        }
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring = False


class CPUOptimizer:
    """CPU ìµœì í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or min(4, os.cpu_count() or 1)
        self.thread_pool = ThreadPoolExecutor(max_workers=self.max_workers)
        self.cpu_stats = deque(maxlen=1000)
        self.process_stats = defaultdict(list)
        
        self.logger = logging.getLogger(__name__)
    
    def get_cpu_usage(self) -> Dict[str, Any]:
        """CPU ì‚¬ìš©ëŸ‰"""
        process = psutil.Process()
        
        cpu_usage = {
            'process_percent': process.cpu_percent(interval=1),
            'system_percent': psutil.cpu_percent(interval=1),
            'cpu_count': psutil.cpu_count(),
            'load_avg': os.getloadavg() if hasattr(os, 'getloadavg') else [0, 0, 0],
            'threads': process.num_threads(),
            'context_switches': process.num_ctx_switches() if hasattr(process, 'num_ctx_switches') else None
        }
        
        self.cpu_stats.append({
            'timestamp': time.time(),
            'usage': cpu_usage
        })
        
        return cpu_usage
    
    def optimize_cpu_bound_task(self, func: Callable, *args, **kwargs):
        """CPU ì§‘ì•½ì  ì‘ì—… ìµœì í™”"""
        return self.thread_pool.submit(func, *args, **kwargs)
    
    async def optimize_async_cpu_task(self, func: Callable, *args, **kwargs):
        """ë¹„ë™ê¸° CPU ì‘ì—… ìµœì í™”"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, func, *args, **kwargs)
    
    def get_cpu_stats(self) -> Dict[str, Any]:
        """CPU í†µê³„"""
        if not self.cpu_stats:
            return {"message": "No CPU data available"}
        
        recent_stats = list(self.cpu_stats)[-100:]  # ìµœê·¼ 100ê°œ
        cpu_values = [s['usage']['process_percent'] for s in recent_stats]
        
        return {
            'current_usage': self.get_cpu_usage(),
            'avg_cpu_percent': sum(cpu_values) / len(cpu_values),
            'max_cpu_percent': max(cpu_values),
            'max_workers': self.max_workers,
            'active_threads': threading.active_count()
        }


class SmartCache:
    """ì§€ëŠ¥í˜• ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 3600):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self.cache = {}
        self.access_times = {}
        self.hit_count = 0
        self.miss_count = 0
        
        # TTL ì •ë¦¬ ìŠ¤ë ˆë“œ
        self.cleanup_thread = threading.Thread(target=self._cleanup_expired, daemon=True)
        self.cleanup_thread.start()
    
    def _cleanup_expired(self):
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        while True:
            try:
                current_time = time.time()
                expired_keys = []
                
                for key, (value, timestamp) in self.cache.items():
                    if current_time - timestamp > self.ttl_seconds:
                        expired_keys.append(key)
                
                for key in expired_keys:
                    self.cache.pop(key, None)
                    self.access_times.pop(key, None)
                
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì •ë¦¬
                
            except Exception:
                time.sleep(60)
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        if key in self.cache:
            value, timestamp = self.cache[key]
            if time.time() - timestamp <= self.ttl_seconds:
                self.access_times[key] = time.time()
                self.hit_count += 1
                return value
            else:
                # ë§Œë£Œëœ í•­ëª© ì œê±°
                self.cache.pop(key, None)
                self.access_times.pop(key, None)
        
        self.miss_count += 1
        return None
    
    def set(self, key: str, value: Any):
        """ìºì‹œì— ê°’ ì €ì¥"""
        current_time = time.time()
        
        # í¬ê¸° ì œí•œ í™•ì¸
        if len(self.cache) >= self.max_size:
            self._evict_lru()
        
        self.cache[key] = (value, current_time)
        self.access_times[key] = current_time
    
    def _evict_lru(self):
        """LRU ê¸°ë°˜ í•­ëª© ì œê±°"""
        if not self.access_times:
            return
        
        # ê°€ì¥ ì˜¤ë˜ ì‚¬ìš©ë˜ì§€ ì•Šì€ í•­ëª© ì œê±°
        lru_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
        self.cache.pop(lru_key, None)
        self.access_times.pop(lru_key, None)
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        total_requests = self.hit_count + self.miss_count
        hit_rate = (self.hit_count / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'size': len(self.cache),
            'max_size': self.max_size,
            'hit_count': self.hit_count,
            'miss_count': self.miss_count,
            'hit_rate_percent': hit_rate,
            'ttl_seconds': self.ttl_seconds
        }
    
    def clear(self):
        """ìºì‹œ ë¹„ìš°ê¸°"""
        self.cache.clear()
        self.access_times.clear()


class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” í†µí•© ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.memory_manager = MemoryManager()
        self.cpu_optimizer = CPUOptimizer()
        self.cache = SmartCache()
        
        self.logger = logging.getLogger(__name__)
        self.optimization_history = deque(maxlen=100)
        
    def optimize_function(self, cache_key: str = None, cpu_bound: bool = False):
        """í•¨ìˆ˜ ìµœì í™” ë°ì½”ë ˆì´í„°"""
        def decorator(func: Callable) -> Callable:
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                # ìºì‹œ í™•ì¸
                if cache_key:
                    cache_result = self.cache.get(f"{func.__name__}:{cache_key}")
                    if cache_result is not None:
                        return cache_result
                
                # CPU ì§‘ì•½ì  ì‘ì—… ì²˜ë¦¬
                if cpu_bound:
                    result = await self.cpu_optimizer.optimize_async_cpu_task(func, *args, **kwargs)
                else:
                    result = await func(*args, **kwargs)
                
                # ê²°ê³¼ ìºì‹±
                if cache_key:
                    self.cache.set(f"{func.__name__}:{cache_key}", result)
                
                return result
            
            @wraps(func)
            def sync_wrapper(*args, **kwargs):
                # ìºì‹œ í™•ì¸
                if cache_key:
                    cache_result = self.cache.get(f"{func.__name__}:{cache_key}")
                    if cache_result is not None:
                        return cache_result
                
                # CPU ì§‘ì•½ì  ì‘ì—… ì²˜ë¦¬
                if cpu_bound:
                    future = self.cpu_optimizer.optimize_cpu_bound_task(func, *args, **kwargs)
                    result = future.result()
                else:
                    result = func(*args, **kwargs)
                
                # ê²°ê³¼ ìºì‹±
                if cache_key:
                    self.cache.set(f"{func.__name__}:{cache_key}", result)
                
                return result
            
            if asyncio.iscoroutinefunction(func):
                return async_wrapper
            else:
                return sync_wrapper
        
        return decorator
    
    @contextmanager
    def performance_context(self, label: str = ""):
        """ì„±ëŠ¥ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        start_time = time.time()
        start_memory = self.memory_manager.get_memory_usage()
        start_cpu = self.cpu_optimizer.get_cpu_usage()
        
        try:
            yield self
        finally:
            end_time = time.time()
            end_memory = self.memory_manager.get_memory_usage()
            end_cpu = self.cpu_optimizer.get_cpu_usage()
            
            performance_data = {
                'label': label,
                'timestamp': datetime.now().isoformat(),
                'duration_seconds': end_time - start_time,
                'memory_delta_mb': end_memory['rss_mb'] - start_memory['rss_mb'],
                'cpu_usage_avg': (start_cpu['process_percent'] + end_cpu['process_percent']) / 2,
                'start_memory_mb': start_memory['rss_mb'],
                'end_memory_mb': end_memory['rss_mb']
            }
            
            self.optimization_history.append(performance_data)
            self.logger.info(f"Performance context '{label}': {performance_data['duration_seconds']:.2f}s, "
                           f"Memory: {performance_data['memory_delta_mb']:+.2f}MB")
    
    def get_system_health(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ"""
        memory_usage = self.memory_manager.get_memory_usage()
        cpu_usage = self.cpu_optimizer.get_cpu_usage()
        cache_stats = self.cache.get_stats()
        
        # ê±´ê°• ì ìˆ˜ ê³„ì‚° (0-100)
        health_score = 100
        
        # ë©”ëª¨ë¦¬ ì ìˆ˜ (ìµœëŒ€ -40ì )
        if memory_usage['percent'] > 90:
            health_score -= 40
        elif memory_usage['percent'] > 80:
            health_score -= 20
        elif memory_usage['percent'] > 70:
            health_score -= 10
        
        # CPU ì ìˆ˜ (ìµœëŒ€ -30ì )
        if cpu_usage['process_percent'] > 80:
            health_score -= 30
        elif cpu_usage['process_percent'] > 60:
            health_score -= 15
        elif cpu_usage['process_percent'] > 40:
            health_score -= 5
        
        # ìºì‹œ ì ìˆ˜ (ìµœëŒ€ -20ì )
        if cache_stats['hit_rate_percent'] < 50:
            health_score -= 20
        elif cache_stats['hit_rate_percent'] < 70:
            health_score -= 10
        elif cache_stats['hit_rate_percent'] < 85:
            health_score -= 5
        
        # ìŠ¤ì™‘ ì‚¬ìš©ëŸ‰ (ìµœëŒ€ -10ì )
        if memory_usage['swap_mb'] > 100:
            health_score -= 10
        elif memory_usage['swap_mb'] > 50:
            health_score -= 5
        
        health_status = "Excellent" if health_score >= 90 else \
                       "Good" if health_score >= 75 else \
                       "Fair" if health_score >= 60 else \
                       "Poor" if health_score >= 40 else "Critical"
        
        return {
            'health_score': max(0, health_score),
            'health_status': health_status,
            'memory_usage': memory_usage,
            'cpu_usage': cpu_usage,
            'cache_stats': cache_stats,
            'recommendations': self._generate_recommendations(memory_usage, cpu_usage, cache_stats)
        }
    
    def _generate_recommendations(self, memory_usage, cpu_usage, cache_stats) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if memory_usage['percent'] > 80:
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ì„ ì‹¤í–‰í•˜ê±°ë‚˜ ë¶ˆí•„ìš”í•œ ê°ì²´ë¥¼ ì •ë¦¬í•˜ì„¸ìš”.")
        
        if cpu_usage['process_percent'] > 70:
            recommendations.append("CPU ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. CPU ì§‘ì•½ì  ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì´ë™í•˜ì„¸ìš”.")
        
        if cache_stats['hit_rate_percent'] < 70:
            recommendations.append("ìºì‹œ íˆíŠ¸ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ìºì‹± ì „ëµì„ ê²€í† í•˜ì„¸ìš”.")
        
        if memory_usage['swap_mb'] > 50:
            recommendations.append("ìŠ¤ì™‘ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•˜ê±°ë‚˜ ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•˜ì„¸ìš”.")
        
        if len(recommendations) == 0:
            recommendations.append("ì‹œìŠ¤í…œì´ ìµœì í™”ëœ ìƒíƒœì…ë‹ˆë‹¤.")
        
        return recommendations
    
    def auto_optimize(self) -> Dict[str, Any]:
        """ìë™ ìµœì í™” ì‹¤í–‰"""
        optimization_results = {}
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        memory_result = self.memory_manager.optimize_memory()
        optimization_results['memory'] = memory_result
        
        # ìºì‹œ ì •ë¦¬ (íˆíŠ¸ë¥ ì´ ë‚®ì€ ê²½ìš°)
        cache_stats = self.cache.get_stats()
        if cache_stats['hit_rate_percent'] < 50:
            self.cache.clear()
            optimization_results['cache'] = {'action': 'cleared', 'reason': 'low hit rate'}
        
        return optimization_results
    
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """ì¢…í•© ì„±ëŠ¥ í†µê³„"""
        return {
            'timestamp': datetime.now().isoformat(),
            'system_health': self.get_system_health(),
            'memory_stats': self.memory_manager.get_memory_stats(),
            'cpu_stats': self.cpu_optimizer.get_cpu_stats(),
            'cache_stats': self.cache.get_stats(),
            'optimization_history': list(self.optimization_history)[-10:],  # ìµœê·¼ 10ê°œ
            'process_info': {
                'pid': os.getpid(),
                'threads': threading.active_count(),
                'file_descriptors': len(os.listdir('/proc/self/fd')) if os.path.exists('/proc/self/fd') else 'N/A'
            }
        }


# ì „ì—­ ìµœì í™”ê¸° ì¸ìŠ¤í„´ìŠ¤
global_optimizer = PerformanceOptimizer()


# í¸ì˜ í•¨ìˆ˜ë“¤
def optimize(cache_key: str = None, cpu_bound: bool = False):
    """ìµœì í™” ë°ì½”ë ˆì´í„° (í¸ì˜ í•¨ìˆ˜)"""
    return global_optimizer.optimize_function(cache_key=cache_key, cpu_bound=cpu_bound)


def performance_context(label: str = ""):
    """ì„±ëŠ¥ ì»¨í…ìŠ¤íŠ¸ (í¸ì˜ í•¨ìˆ˜)"""
    return global_optimizer.performance_context(label)


def system_health():
    """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ (í¸ì˜ í•¨ìˆ˜)"""
    return global_optimizer.get_system_health()


def auto_optimize():
    """ìë™ ìµœì í™” (í¸ì˜ í•¨ìˆ˜)"""
    return global_optimizer.auto_optimize()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    
    # ìµœì í™” ì˜ˆì‹œ
    @optimize(cache_key="example", cpu_bound=True)
    def cpu_intensive_function(n: int):
        return sum(i * i for i in range(n))
    
    @optimize(cache_key="async_example")
    async def async_function():
        await asyncio.sleep(0.1)
        return "async result"
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    async def test_performance_system():
        print("âš¡ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        
        with performance_context("performance_test"):
            # CPU ì§‘ì•½ì  ì‘ì—…
            result1 = cpu_intensive_function(10000)
            print(f"CPU ì§‘ì•½ì  ì‘ì—… ê²°ê³¼: {result1}")
            
            # ë¹„ë™ê¸° ì‘ì—…
            result2 = await async_function()
            print(f"ë¹„ë™ê¸° ì‘ì—… ê²°ê³¼: {result2}")
            
            # ìºì‹œëœ ê²°ê³¼ (ë‘ ë²ˆì§¸ í˜¸ì¶œ)
            result3 = cpu_intensive_function(10000)
            print(f"ìºì‹œëœ ê²°ê³¼: {result3}")
        
        # ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ í™•ì¸
        health = system_health()
        print(f"\nğŸ¥ ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ: {health['health_status']} ({health['health_score']}/100)")
        
        # ìë™ ìµœì í™”
        optimization_result = auto_optimize()
        print(f"ğŸ”§ ìë™ ìµœì í™” ê²°ê³¼: {optimization_result}")
        
        # ì¢…í•© í†µê³„
        stats = global_optimizer.get_comprehensive_stats()
        print(f"\nğŸ“Š ì¢…í•© ì„±ëŠ¥ í†µê³„:")
        print(json.dumps(stats, indent=2, default=str))
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_performance_system())