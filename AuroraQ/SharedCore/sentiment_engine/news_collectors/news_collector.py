#!/usr/bin/env python3
"""
News Collector - ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±
ê¸°ì¡´ sentiment_engineì—ì„œ ì‚¬ìš©í•˜ë˜ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜ë˜ëŠ” ìƒˆë¡œìš´ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°
"""

import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import logging
from dataclasses import dataclass

# ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì„í¬íŠ¸
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

from data_collection.news_aggregation_system import AuroraQNewsAggregator
from data_collection.base_collector import NewsArticle, NewsCategory


# í•˜ìœ„í˜¸í™˜ì„ ìœ„í•œ ë°ì´í„° í´ë˜ìŠ¤ (ê¸°ì¡´ í˜•íƒœ ìœ ì§€)
@dataclass
class LegacyNewsArticle:
    """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ìš© ë‰´ìŠ¤ ê¸°ì‚¬ (í•˜ìœ„í˜¸í™˜)"""
    id: str
    title: str
    summary: str
    content: str
    url: str
    published: datetime
    source: str
    author: Optional[str]
    keywords: List[str]
    engagement: Dict[str, int]
    
    @classmethod
    def from_new_article(cls, article: NewsArticle) -> 'LegacyNewsArticle':
        """ìƒˆë¡œìš´ NewsArticleì„ ê¸°ì¡´ í˜•íƒœë¡œ ë³€í™˜"""
        return cls(
            id=article.id,
            title=article.title,
            summary=article.summary,
            content=article.content,
            url=article.url,
            published=article.published_date,
            source=article.source,
            author=article.author,
            keywords=article.keywords,
            engagement={'count': article.metadata.get('score', 0) if article.metadata else 0}
        )


class NewsCollector:
    """
    í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°
    ê¸°ì¡´ ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ë˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ ì‹œìŠ¤í…œ í™œìš©
    """
    
    def __init__(self, access_token: Optional[str] = None):
        self.logger = logging.getLogger(__name__)
        
        # ìƒˆë¡œìš´ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.aggregator = AuroraQNewsAggregator()
        
        # ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„ ìœ„í•œ ì„¤ì •
        self.crypto_keywords = {
            'bitcoin', 'btc', 'ethereum', 'eth', 'cryptocurrency', 'crypto',
            'blockchain', 'defi', 'nft', 'altcoin', 'binance', 'coinbase'
        }
        
        # ê°ì • ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œ
        self.sentiment_keywords = {
            'positive': {
                'bull', 'bullish', 'moon', 'pump', 'surge', 'rally',
                'breakthrough', 'adoption', 'partnership', 'launch',
                'upgrade', 'milestone', 'success', 'growth', 'rise'
            },
            'negative': {
                'bear', 'bearish', 'crash', 'dump', 'fall', 'drop',
                'hack', 'scam', 'regulation', 'ban', 'concern',
                'risk', 'decline', 'loss', 'sell-off', 'correction'
            }
        }
        
        self.logger.info("NewsCollector initialized with new aggregation system")
    
    async def connect(self):
        """ì—°ê²° í™•ì¸ (í•˜ìœ„í˜¸í™˜ìš©)"""
        try:
            health = await self.aggregator.get_system_health()
            if health.get('status') == 'healthy':
                self.logger.info(f"Connected to news aggregation system")
                self.logger.info(f"Active collectors: {health.get('active_collectors', 0)}")
            else:
                self.logger.warning(f"System status: {health.get('status')}")
        except Exception as e:
            self.logger.warning(f"Connection check failed: {e}")
    
    async def get_latest_crypto_news(self, hours_back: int = 24, max_articles: int = 200) -> List[LegacyNewsArticle]:
        """ìµœì‹  ì•”í˜¸í™”í ë‰´ìŠ¤ ìˆ˜ì§‘ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
        self.logger.info(f"Collecting crypto news from last {hours_back} hours...")
        
        try:
            # ìƒˆë¡œìš´ ì‹œìŠ¤í…œìœ¼ë¡œ ì•”í˜¸í™”í ë‰´ìŠ¤ ìˆ˜ì§‘
            news_data = await self.aggregator.collect_comprehensive_news(
                categories=[NewsCategory.CRYPTO],
                hours_back=hours_back,
                articles_per_category=max_articles
            )
            
            crypto_articles = news_data.get('crypto', [])
            
            # ê¸°ì¡´ í˜•íƒœë¡œ ë³€í™˜
            legacy_articles = []
            for article in crypto_articles[:max_articles]:
                legacy_article = LegacyNewsArticle.from_new_article(article)
                legacy_articles.append(legacy_article)
            
            self.logger.info(f"Collected {len(legacy_articles)} crypto articles")
            return legacy_articles
            
        except Exception as e:
            self.logger.error(f"Error collecting crypto news: {e}")
            return []
    
    async def search_crypto_news(self, keywords: List[str], hours: int = 24) -> List[LegacyNewsArticle]:
        """ì•”í˜¸í™”í ë‰´ìŠ¤ ê²€ìƒ‰ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
        try:
            since = datetime.now() - timedelta(hours=hours)
            
            # ìƒˆë¡œìš´ ì‹œìŠ¤í…œìœ¼ë¡œ ê²€ìƒ‰
            articles = await self.aggregator.search_all_sources(
                keywords=keywords,
                since=since,
                count_per_source=50
            )
            
            # ì•”í˜¸í™”í ê´€ë ¨ í•„í„°ë§
            crypto_articles = []
            for article in articles:
                if self._is_crypto_relevant_new(article):
                    crypto_articles.append(article)
            
            # ê¸°ì¡´ í˜•íƒœë¡œ ë³€í™˜
            legacy_articles = []
            for article in crypto_articles:
                legacy_article = LegacyNewsArticle.from_new_article(article)
                legacy_articles.append(legacy_article)
            
            return legacy_articles
            
        except Exception as e:
            self.logger.error(f"Error searching crypto news: {e}")
            return []
    
    def _is_crypto_relevant_new(self, article: NewsArticle) -> bool:
        """ìƒˆë¡œìš´ NewsArticleì´ ì•”í˜¸í™”í ê´€ë ¨ì¸ì§€ í™•ì¸"""
        # ì¹´í…Œê³ ë¦¬ í™•ì¸
        if article.category == NewsCategory.CRYPTO:
            return True
        
        # í‚¤ì›Œë“œ í™•ì¸
        text = (article.title + ' ' + article.summary).lower()
        for keyword in self.crypto_keywords:
            if keyword in text:
                return True
        
        return False
    
    async def search_btc_news(self, hours: int = 24) -> List[LegacyNewsArticle]:
        """BTC ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰"""
        return await self.search_crypto_news(["bitcoin", "btc"], hours)
    
    async def search_eth_news(self, hours: int = 24) -> List[LegacyNewsArticle]:
        """ETH ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰"""
        return await self.search_crypto_news(["ethereum", "eth"], hours)
    
    async def search_defi_news(self, hours: int = 24) -> List[LegacyNewsArticle]:
        """DeFi ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰"""
        return await self.search_crypto_news(["defi", "decentralized finance"], hours)
    
    async def search_regulation_news(self, hours: int = 48) -> List[LegacyNewsArticle]:
        """ê·œì œ ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰"""
        return await self.search_crypto_news(["crypto regulation", "sec crypto", "bitcoin etf"], hours)
    
    async def search_altcoin_news(self, symbols: List[str], hours: int = 24) -> List[LegacyNewsArticle]:
        """ì•ŒíŠ¸ì½”ì¸ ë‰´ìŠ¤ ê²€ìƒ‰"""
        keywords = symbols + [f"{symbol} price" for symbol in symbols]
        return await self.search_crypto_news(keywords, hours)
    
    async def get_trending_crypto_news(self, count: int = 20) -> List[LegacyNewsArticle]:
        """íŠ¸ë Œë”© ì•”í˜¸í™”í ë‰´ìŠ¤"""
        try:
            # ì†ë³´ì—ì„œ ì•”í˜¸í™”í ê´€ë ¨ í•„í„°ë§
            breaking_news = await self.aggregator.get_breaking_news_all(minutes=180)  # 3ì‹œê°„
            
            crypto_breaking = []
            for article in breaking_news:
                if self._is_crypto_relevant_new(article):
                    crypto_breaking.append(article)
            
            # ê¸°ì¡´ í˜•íƒœë¡œ ë³€í™˜
            legacy_articles = []
            for article in crypto_breaking[:count]:
                legacy_article = LegacyNewsArticle.from_new_article(article)
                legacy_articles.append(legacy_article)
            
            return legacy_articles
            
        except Exception as e:
            self.logger.error(f"Error getting trending news: {e}")
            return []
    
    async def get_market_sentiment_articles(self, hours: int = 6) -> Dict[str, List[LegacyNewsArticle]]:
        """ì‹œì¥ ê°ì •ë³„ë¡œ ë¶„ë¥˜ëœ ê¸°ì‚¬ë“¤ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
        try:
            # ìµœê·¼ ì•”í˜¸í™”í ë‰´ìŠ¤ ìˆ˜ì§‘
            crypto_articles = await self.get_latest_crypto_news(hours_back=hours, max_articles=100)
            
            # ê°ì •ë³„ ë¶„ë¥˜
            sentiment_articles = {
                'positive': [],
                'negative': [],
                'neutral': []
            }
            
            for article in crypto_articles:
                sentiment = self._classify_sentiment_legacy(article)
                sentiment_articles[sentiment].append(article)
            
            return sentiment_articles
            
        except Exception as e:
            self.logger.error(f"Error analyzing market sentiment: {e}")
            return {'positive': [], 'negative': [], 'neutral': []}
    
    def _classify_sentiment_legacy(self, article: LegacyNewsArticle) -> str:
        """ê¸°ì¡´ ë°©ì‹ì˜ ê°ì • ë¶„ë¥˜"""
        text = (article.title + " " + article.summary).lower()
        
        positive_count = sum(1 for word in self.sentiment_keywords['positive'] if word in text)
        negative_count = sum(1 for word in self.sentiment_keywords['negative'] if word in text)
        
        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'
    
    async def get_symbol_specific_news(self, symbol: str, hours: int = 24) -> List[LegacyNewsArticle]:
        """íŠ¹ì • ì‹¬ë³¼ì— ëŒ€í•œ ë‰´ìŠ¤"""
        keywords = [symbol, f"{symbol} price", f"{symbol} news"]
        return await self.search_crypto_news(keywords, hours)
    
    async def get_breaking_news(self, minutes: int = 30) -> List[LegacyNewsArticle]:
        """ìµœê·¼ ì†ë³´"""
        try:
            breaking_articles = await self.aggregator.get_breaking_news_all(minutes=minutes)
            
            # ì•”í˜¸í™”í ê´€ë ¨ë§Œ í•„í„°ë§
            crypto_breaking = []
            for article in breaking_articles:
                if self._is_crypto_relevant_new(article):
                    crypto_breaking.append(article)
            
            # ê¸°ì¡´ í˜•íƒœë¡œ ë³€í™˜
            legacy_articles = []
            for article in crypto_breaking:
                legacy_article = LegacyNewsArticle.from_new_article(article)
                legacy_articles.append(legacy_article)
            
            return legacy_articles
            
        except Exception as e:
            self.logger.error(f"Error getting breaking news: {e}")
            return []
    
    def calculate_basic_sentiment(self, article: LegacyNewsArticle) -> Dict[str, float]:
        """ê¸°ë³¸ì ì¸ ê°ì • ì ìˆ˜ ê³„ì‚° (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
        text = (article.title + ' ' + article.summary).lower()
        
        positive_count = 0
        negative_count = 0
        
        # ê¸ì • í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
        for keyword in self.sentiment_keywords['positive']:
            positive_count += text.count(keyword)
        
        # ë¶€ì • í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
        for keyword in self.sentiment_keywords['negative']:
            negative_count += text.count(keyword)
        
        total_count = positive_count + negative_count
        
        if total_count == 0:
            sentiment_score = 0.5  # ì¤‘ë¦½
        else:
            sentiment_score = positive_count / total_count
        
        # ì°¸ì—¬ë„ ê°€ì¤‘ì¹˜ ì ìš©
        engagement_weight = min(1.0, article.engagement.get('count', 0) / 100)
        
        return {
            'sentiment': sentiment_score,
            'confidence': min(0.8, total_count * 0.1 + engagement_weight),
            'positive_signals': positive_count,
            'negative_signals': negative_count,
            'engagement_weight': engagement_weight
        }
    
    async def get_sentiment_summary(self, articles: List[LegacyNewsArticle]) -> Dict[str, Any]:
        """ê¸°ì‚¬ë“¤ì˜ ê°ì • ìš”ì•½ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
        if not articles:
            return {
                'overall_sentiment': 0.5,
                'confidence': 0.0,
                'article_count': 0,
                'positive_count': 0,
                'negative_count': 0,
                'neutral_count': 0
            }
        
        sentiments = []
        confidences = []
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        
        for article in articles:
            sentiment_data = self.calculate_basic_sentiment(article)
            sentiment = sentiment_data['sentiment']
            confidence = sentiment_data['confidence']
            
            sentiments.append(sentiment)
            confidences.append(confidence)
            
            if sentiment > 0.6:
                positive_count += 1
            elif sentiment < 0.4:
                negative_count += 1
            else:
                neutral_count += 1
        
        # ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        if sum(confidences) > 0:
            weighted_sentiment = sum(s * c for s, c in zip(sentiments, confidences)) / sum(confidences)
            avg_confidence = sum(confidences) / len(confidences)
        else:
            weighted_sentiment = 0.5
            avg_confidence = 0.0
        
        return {
            'overall_sentiment': weighted_sentiment,
            'confidence': avg_confidence,
            'article_count': len(articles),
            'positive_count': positive_count,
            'negative_count': negative_count,
            'neutral_count': neutral_count,
            'sentiment_distribution': {
                'positive': positive_count / len(articles),
                'negative': negative_count / len(articles),
                'neutral': neutral_count / len(articles)
            }
        }
    
    async def get_collection_stats(self) -> Dict[str, Any]:
        """ìˆ˜ì§‘ í†µê³„ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
        try:
            health = await self.aggregator.get_system_health()
            
            return {
                "status": health.get("status", "unknown"),
                "client_available": health.get("active_collectors", 0) > 0,
                "api_stats": {
                    "total_articles": health.get("collection_stats", {}).get("total_articles", 0)
                },
                "rate_limit": {},
                "cache_size": 0
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "client_available": False
            }
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            await self.aggregator.close_all()
            self.logger.info("NewsCollector closed")
        except Exception as e:
            self.logger.error(f"Error closing NewsCollector: {e}")


# íŒ©í† ë¦¬ í•¨ìˆ˜ (ê¸°ì¡´ í˜¸í™˜ì„±)
def create_news_collector(access_token: Optional[str] = None) -> NewsCollector:
    """ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ìƒì„± (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
    return NewsCollector(access_token=access_token)


# ì‚¬ìš© ì˜ˆì œ
async def main():
    """í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    collector = NewsCollector()
    
    try:
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        await collector.connect()
        
        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
        print("ğŸ“° Collecting latest crypto news...")
        articles = await collector.get_latest_crypto_news(hours_back=6, max_articles=10)
        print(f"Found {len(articles)} articles")
        
        for article in articles[:3]:
            print(f"\n- {article.title}")
            print(f"  Source: {article.source}")
            print(f"  Published: {article.published}")
        
        # ê°ì • ë¶„ì„
        print("\nğŸ’­ Analyzing sentiment...")
        sentiment_summary = await collector.get_sentiment_summary(articles)
        print(f"Overall sentiment: {sentiment_summary['overall_sentiment']:.2f}")
        print(f"Article distribution: {sentiment_summary['sentiment_distribution']}")
        
        # ì†ë³´ í™•ì¸
        print("\nğŸš¨ Breaking news...")
        breaking = await collector.get_breaking_news(minutes=60)
        print(f"Found {len(breaking)} breaking news")
        
        # í†µê³„
        stats = await collector.get_collection_stats()
        print(f"\nğŸ“Š Stats: {stats}")
        
    finally:
        await collector.close()


if __name__ == "__main__":
    asyncio.run(main())